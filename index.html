<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Recognition</title>
    <script src="https://gcore.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://gcore.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script src="https://gcore.jsdelivr.net/npm/face-api.js"></script>
    <style>
        video {
            width: 100%;
            max-width: 600px;
            border: 2px solid black;
        }
        #status {
            margin-top: 20px;
            font-size: 20px;
            color: red;
        }
    </style>
</head>
<body>
    <h1>Camera Recognition</h1>
    <video id="video" autoplay muted></video>
    <div id="status"></div>

    <script>
        async function setupCamera() {
            const video = document.getElementById('video');
            const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        }

        async function detectFaces(video) {
            const detections = await faceapi.detectAllFaces(video);
            return detections.length > 0;
        }

        async function detectPose(video) {
            const net = await posenet.load();
            const pose = await net.estimateSinglePose(video, {
                flipHorizontal: false
            });
            return pose.score > 0.5 && pose.keypoints.some(kp => kp.part === 'nose' && kp.position.y < 100);
        }

        async function main() {
            const video = await setupCamera();
            await loadModels();

            setInterval(async () => {
                const hasFace = await detectFaces(video);
                const isStanding = await detectPose(video);

                const statusElement = document.getElementById('status');
                if (hasFace) {
                    statusElement.textContent = 'Face detected!';
                } else if (isStanding) {
                    statusElement.textContent = 'Standing detected!';
                } else {
                    statusElement.textContent = '';
                }
            }, 1000);
        }

        main();
    </script>
</body>
</html>
